# Phi3-EdgeQuant-Agent

**Phi3-EdgeQuant-Agent** is an advanced project focused on deploying a **quantized Phi-3-mini (3.8B) LLM agent** on edge devices. Built with high efficiency and research-grade modularity, it leverages quantization techniques to enable large language models to run on low-resource hardware such as laptops or edge accelerators.

> Target Audience: Researchers, AI Engineers, ML Edge Developers, and Open-Source Contributors

## ğŸ” Objective

To build a **self-quantizing Phi3 LLM agent** that can:

* Operate efficiently on edge devices (e.g., RTX 3050, Jetson, RPi 5 with accelerator).
* Preserve inference capabilities close to full precision.
* Serve as a modular base for further development (e.g., AutoGen agents, RAG systems, embedded NLP tools).

## ğŸš€ Features

* âœ… Loads and quantizes Phi-3-mini (3.8B) locally
* âœ… Structured scripts for inference, quantization, and model loading
* âœ… Edge-optimized with 8-bit quantization support
* âœ… Clear directory and modular Python scripts
* âœ… Clean integration with future AutoGen or RAG-based agents

## ğŸ› Architecture

```
Phi3-EdgeQuant-Agent/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_agent.py               # Entry point for agent execution
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model_loader/
â”‚   â”‚   â”œâ”€â”€ download_phi3_model.py   # Downloads Phi-3-mini to local path
â”‚   â”‚   â””â”€â”€ inference_phi3_local.py # Handles local inference
â”‚   â””â”€â”€ quantization/
â”‚       â””â”€â”€ quantize_phi3_8bit.py   # Quantizes model to 8-bit
```

## ğŸ“š Setup

### 1. Clone Repo

```bash
git clone https://github.com/pyschofives/Phi3-EdgeQuant-Agent.git
cd Phi3-EdgeQuant-Agent
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Download Model

```bash
python src/model_loader/download_phi3_model.py
```

> Downloads Phi-3-mini to `models/` directory

### 4. Quantize the Model

```bash
python src/quantization/quantize_phi3_8bit.py
```

### 5. Run Inference

```bash
python scripts/run_agent.py
```

## ğŸ”¢ Model Used

* `microsoft/Phi-3-mini-4k-instruct`
* Quantized using `bitsandbytes`, `transformers`, and `AutoGPTQ` (optional extension)

## ğŸŒ Applications

* Offline LLM agents on laptops and embedded systems
* R\&D in LLM compression and deployment
* Integration with lightweight assistant UIs

## âœ¨ Coming Soon

* âœ… AutoGen agent wrapper
* âœ… Performance benchmarks vs FP16
* âœ… Dynamic quantization + on-device chat GUI
* âœ… Paper-ready experiments + Colab notebook

## ğŸš© Contributions

PRs are welcome. For major changes, open an issue first to discuss what you would like to change.

## ğŸ“… License

MIT License

---

Maintained by **CudaBit Team**
Lead Developer: [Stifler (AI Engineer)](https://github.com/STiFLeR7)

---

**If you like this repo, please give it a star!** âœ¨
